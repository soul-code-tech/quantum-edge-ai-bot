import os
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam
import pickle
import time

class LSTMPredictor:
    def __init__(self, lookback=60, model_dir='weights'):
        self.lookback = lookback
        self.model_dir = model_dir
        self.model = None
        self.scaler = MinMaxScaler()
        self.feature_columns = ['close', 'volume', 'rsi', 'sma20', 'sma50', 'atr']
        self.model_path = None
        self.scaler_path = None
        self.last_training_time = 0
        
    def _get_model_paths(self, symbol):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—É—Ç–∏ –¥–ª—è –º–æ–¥–µ–ª–∏ –∏ —Å–∫–µ–π–ª–µ—Ä–∞ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞"""
        safe_symbol = symbol.replace('-', '_').replace('/', '_')
        model_filename = f"lstm_{safe_symbol}.weights.h5"
        scaler_filename = f"lstm_{safe_symbol}_scaler.pkl"
        
        model_path = os.path.join(self.model_dir, model_filename)
        scaler_path = os.path.join(self.model_dir, scaler_filename)
        
        return model_path, scaler_path
    
    def _create_model(self, input_shape):
        """–°–æ–∑–¥–∞–µ—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É LSTM –º–æ–¥–µ–ª–∏"""
        model = Sequential([
            LSTM(50, return_sequences=True, input_shape=input_shape),
            Dropout(0.2),
            LSTM(50, return_sequences=True),
            Dropout(0.2),
            LSTM(50),
            Dropout(0.2),
            Dense(25),
            Dense(1, activation='sigmoid')
        ])
        
        model.compile(
            optimizer=Adam(learning_rate=0.001),
            loss='binary_crossentropy',
            metrics=['accuracy']
        )
        
        return model
    
    def _prepare_features(self, df):
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        features_df = df[self.feature_columns].copy()
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –∫–∞–∫ –ø—Ä–∏–∑–Ω–∞–∫–∏
        features_df['price_change'] = features_df['close'].pct_change()
        features_df['volume_change'] = features_df['volume'].pct_change()
        features_df['rsi_norm'] = features_df['rsi'] / 100.0
        features_df['sma_ratio'] = features_df['sma20'] / features_df['sma50']
        features_df['atr_norm'] = features_df['atr'] / features_df['close']
        
        # –£–¥–∞–ª—è–µ–º NaN –∑–Ω–∞—á–µ–Ω–∏—è
        features_df = features_df.dropna()
        
        return features_df
    
    def _create_sequences(self, data, labels=None):
        """–°–æ–∑–¥–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è LSTM"""
        sequences = []
        target_labels = []
        
        for i in range(self.lookback, len(data)):
            sequences.append(data[i-self.lookback:i])
            if labels is not None:
                target_labels.append(labels[i])
        
        if labels is not None:
            return np.array(sequences), np.array(target_labels)
        return np.array(sequences)
    
    def load_or_create_model(self, symbol):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –º–æ–¥–µ–ª—å –∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—É—é"""
        self.model_path, self.scaler_path = self._get_model_paths(symbol)
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é weights –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        os.makedirs(self.model_dir, exist_ok=True)
        
        try:
            if os.path.exists(self.model_path) and os.path.exists(self.scaler_path):
                print(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –º–æ–¥–µ–ª–∏ –¥–ª—è {symbol}")
                self.model = load_model(self.model_path)
                with open(self.scaler_path, 'rb') as f:
                    self.scaler = pickle.load(f)
                return True
            else:
                print(f"üÜï –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è {symbol}")
                return False
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ –¥–ª—è {symbol}: {e}")
            return False
    
    def train_model(self, df, symbol, epochs=5, is_initial=True):
        """–û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            print(f"üß† {'–ü–µ—Ä–≤–∏—á–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ' if is_initial else '–î–æ–æ–±—É—á–µ–Ω–∏–µ'} –º–æ–¥–µ–ª–∏ {symbol} –Ω–∞ {epochs} —ç–ø–æ—Ö")
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
            features_df = self._prepare_features(df)
            
            if len(features_df) < self.lookback + 10:
                print(f"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è {symbol}")
                return False
            
            # –°–æ–∑–¥–∞–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é (–±—É–¥–µ—Ç —Ä–∞—Å—Ç–∏ —Ü–µ–Ω–∞ –∏–ª–∏ –Ω–µ—Ç)
            future_returns = features_df['close'].pct_change(5).shift(-5)  # 5 –ø–µ—Ä–∏–æ–¥–æ–≤ –≤–ø–µ—Ä–µ–¥
            labels = (future_returns > 0).astype(int).values
            
            # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
            feature_data = features_df.drop(['close'], axis=1).values  # –£–±–∏—Ä–∞–µ–º close —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ —É—Ç–µ—á–∫–∏
            scaled_features = self.scaler.fit_transform(feature_data)
            
            # –°–æ–∑–¥–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            X, y = self._create_sequences(scaled_features, labels)
            
            if len(X) == 0:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è {symbol}")
                return False
            
            # –°–æ–∑–¥–∞–µ–º –∏–ª–∏ –∑–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
            if self.model is None:
                self.model = self._create_model((X.shape[1], X.shape[2]))
            
            # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
            history = self.model.fit(
                X, y,
                epochs=epochs,
                batch_size=32,
                validation_split=0.1,
                verbose=1,
                shuffle=False
            )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –∏ —Å–∫–µ–π–ª–µ—Ä
            self.model.save(self.model_path)
            with open(self.scaler_path, 'wb') as f:
                pickle.dump(self.scaler, f)
            
            self.last_training_time = time.time()
            
            final_loss = history.history['loss'][-1]
            final_accuracy = history.history['accuracy'][-1]
            print(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ {symbol} –∑–∞–≤–µ—Ä—à–µ–Ω–æ. Loss: {final_loss:.4f}, Accuracy: {final_accuracy:.4f}")
            
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ {symbol}: {e}")
            return False
    
    def predict_next(self, df):
        """–ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–æ—Å—Ç–∞ —Ü–µ–Ω—ã"""
        try:
            if self.model is None:
                print(f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å –¥–ª—è {symbol if 'symbol' in locals() else 'unknown'} –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                return 0.5
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
            features_df = self._prepare_features(df)
            
            if len(features_df) < self.lookback:
                return 0.5
            
            # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ lookback –∑–∞–ø–∏—Å–µ–π
            recent_data = features_df.tail(self.lookback)
            feature_data = recent_data.drop(['close'], axis=1).values
            
            # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
            scaled_features = self.scaler.transform(feature_data)
            
            # –°–æ–∑–¥–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            sequence = scaled_features.reshape(1, self.lookback, -1)
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º
            prediction = self.model.predict(sequence, verbose=0)
            probability = float(prediction[0][0])
            
            return probability
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
            return 0.5
    
    def needs_retraining(self, retrain_interval_minutes=30):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –¥–æ–æ–±—É—á–µ–Ω–∏–µ"""
        current_time = time.time()
        time_since_last_train = current_time - self.last_training_time
        return time_since_last_train >= (retrain_interval_minutes * 60)
